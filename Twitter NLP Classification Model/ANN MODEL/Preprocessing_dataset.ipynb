{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\Twitter NLP Classification Model\\Bro Isep\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import os\n",
    "print(os.getcwd())   # Prints the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Provide the new path here\n",
    "os.chdir('C:\\\\Users\\\\user\\\\Desktop\\\\Twitter NLP Classification Model\\\\DATASET\\\\dataset 31-05-2020')\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df_normalization = pd.read_csv('normalization.csv')\n",
    "dict_1 = df_normalization.set_index('kata tidak baku').T.to_dict('list')\n",
    "df_stopword = pd.read_csv('stopword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fcn(data):\n",
    "    for key, value in dict_1.items():\n",
    "        data = data.replace(' '+key+' ',' '+value[0]+' ')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Text2 = df['Text'])                                               # Add new comparison column text\n",
    "\n",
    "df['Text2'] = df['Text'].replace(r'\\\\n',' ', regex=True)                         # remove new line \n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(r'http\\S+', ' ', x))              # remove url\n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(r'#\\S+', ' ', x))                 # remove hashtag\n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(r'@\\S+', ' ', x))                 # remove username\n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", x)) # remove any digit\n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(r'\\\\\\S+', ' ', x))                # remove \\u00a0 and the other similar code\n",
    "df['Text2'] = df['Text2'].map(lambda x: re.sub(r'[^A-Za-z0-9]+', ' ', x))        # remove special character including emoji\n",
    "df['Text2'] = df['Text2'].str.replace('RT','',case=True)                         # remove RT\n",
    "df['Text2'] = df['Text2'].str.lstrip()                                           # remove whitespace,newline,tab,basically everything from the start of string\n",
    "df['Text2'] = df['Text2'].str.rstrip()                                           # remove whitespace,newline,tab,basically everything from the end of string\n",
    "df['Text2'] = df['Text2'].str.lower()                                            # lowercase\n",
    "\n",
    "\n",
    "df = df.assign(Text3 = df['Text2'])                                              # Create new text for display normalized result\n",
    "df['Text3'] = df['Text2'].map(lambda x: normalize_fcn(x))                        # Normalize\n",
    "\n",
    "######################################\n",
    "#Remove Number\n",
    "######################################\n",
    "df = df.assign(RemoveNumber = df['Text3'])\n",
    "df['RemoveNumber'] = df['Text3'].map(lambda x: re.sub('[0-9]+', ' ', x) )         # remove Number\n",
    "\n",
    "######################################\n",
    "# Stopword\n",
    "#######################################\n",
    "#df = df.assign(Text4 = df['Text3'])                                              # Create new text for display stop word removal result\n",
    "df = df.assign(Text4 = df['RemoveNumber'])                                        # Create new text for display stop word removal result\n",
    "stop_factory = StopWordRemoverFactory().get_stop_words()\n",
    "more_stopword = df_stopword['Stopword'].to_numpy()\n",
    "more_stopword = list(more_stopword) \n",
    "# Merge stopword\n",
    "data_stopword = stop_factory + more_stopword\n",
    "dictionary_stopword = ArrayDictionary(data_stopword)\n",
    "str1 = StopWordRemover(dictionary_stopword)\n",
    "#df['Text4'] = df['Text3'].map(lambda x: str1.remove(x))                         # Stop word\n",
    "df['Text4'] = df['Text4'].map(lambda x: str1.remove(x))                         # Stop word\n",
    "df['Text4'] = df['Text4'].str.lstrip()                                          # remove whitespace,newline,tab,basically everything from the start of string\n",
    "df['Text4'] = df['Text4'].str.rstrip()                                          # remove whitespace,newline,tab,basically everything from the end of string\n",
    "\n",
    "#####################################\n",
    "#Stemming\n",
    "#####################################\n",
    "df = df.assign(Text5 = df['Text4'])  \n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "# stemming process\n",
    "df['Text5'] = df['Text5'].map(lambda x:stemmer.stem(x))\n",
    "df['Text5'] = df['Text5'].str.lstrip()                                          # remove whitespace,newline,tab,basically everything from the start of string\n",
    "df['Text5'] = df['Text5'].str.rstrip()                                          # remove whitespace,newline,tab,basically everything from the end of string\n",
    "\n",
    "# print(df.head(25))\n",
    "df.to_csv('result_prepro3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
